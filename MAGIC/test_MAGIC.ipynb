{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "from typing import Optional\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Monai\n",
    "import monai\n",
    "from monai.data.dataset import Dataset\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric, SurfaceDistanceMetric, CumulativeIterationMetric\n",
    "from monai.data.utils import pad_list_data_collate\n",
    "from monai.losses.dice import DiceCELoss\n",
    "from monai.data.dataloader import DataLoader\n",
    "from monai.inferers.utils import sliding_window_inference\n",
    "import monai.transforms as transform\n",
    "from monai.transforms import AsDiscrete\n",
    "\n",
    "# Other\n",
    "import numpy as np\n",
    "\n",
    "# Local\n",
    "from MAGIC import MAGIC_framework\n",
    "from MagicianAssistant import argmax_with_multiOutput, split_groups_transform, channel_to_stacked_binary_transform\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data sources / preprocessing for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the modality to look at\n",
    "mode = \"VR\"\n",
    "mode_options = [\"VR\", \"simCT\", \"CCTA\"]\n",
    "\n",
    "# Defining the data source\n",
    "master_src = \"path/to/data/location\"\n",
    "\n",
    "# Defining the image keys\n",
    "image_keys = ['image']\n",
    "real_keys = image_keys + ['label']\n",
    "# 'g{i}' represent the sub-groups used in multi-task learning\n",
    "all_keys = image_keys + [f'g{i}' for i in range(4)]\n",
    "\n",
    "# Defining pre-processing steps\n",
    "preprocessing_transforms = [\n",
    "    transform.LoadImaged(real_keys),\n",
    "    split_groups_transform(\n",
    "        target_key='label',\n",
    "        group_idxs=[[0], [1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15, 16, 17], [18, 19]],\n",
    "        out_names=['g0', 'g1', 'g2', 'g3'],\n",
    "        stacking_order=None,\n",
    "        ),\n",
    "    channel_to_stacked_binary_transform('label', 'blabel'),\n",
    "    transform.NormalizeIntensityd(image_keys, nonzero=True), #z-score normalization that helps consistancy with patient to patient and brings mean to zero to help with deep learning\n",
    "]\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# For ViewRay\n",
    "# ----------------------------------------------------------------\n",
    "if mode.upper() == \"VR\":\n",
    "    main_path = os.path.join(master_src, \"VR\")\n",
    "\n",
    "    testing_data = []\n",
    "    HF_testing_pids = [1, 18, 29, 35, 36]\n",
    "    testing_pids = [f'HF_VR_{pid:02d}' for pid in HF_testing_pids]\n",
    "    UW_testing_pids = [1, 2, 3, 4, 5] #, 6, 7, 8, 9, 10]\n",
    "    testing_pids += [f'UW_VR_{pid:02d}' for pid in UW_testing_pids]\n",
    "\n",
    "    for pid in testing_pids:\n",
    "        image_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}_SIM.IMAGE.nii.gz\")))\n",
    "        label_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}_SIM.LABEL.nii.gz\")))\n",
    "        for i in range (len(image_paths)):\n",
    "            testing_data.append({'image': image_paths[i], 'label': label_paths[i]})\n",
    "\n",
    "    testing_dataset = Dataset(testing_data, transform.Compose(preprocessing_transforms))\n",
    "\n",
    "    VR_testing_dataloader = DataLoader(testing_dataset,  num_workers = 1, batch_size = 1, shuffle = False, collate_fn = pad_list_data_collate, pin_memory = True)\n",
    "\n",
    "    testing_sets = [\n",
    "        ('VR', VR_testing_dataloader)\n",
    "    ]\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# For simCT\n",
    "# ----------------------------------------------------------------\n",
    "elif mode.upper() == 'SIMCT':\n",
    "\n",
    "    main_path = os.path.join(master_src, \"simCT\")\n",
    "    HF_testing_pids = [13, 22, 28, 29, 34]\n",
    "    testing_pids = [f'HF_simCT_{pid:02d}' for pid in HF_testing_pids]\n",
    "    UW_testing_pids = [16, 18, 22, 28, 32]\n",
    "    testing_pids += [f'UW_simCT_{pid:02d}' for pid in UW_testing_pids]\n",
    "\n",
    "    testing_data = []\n",
    "    for pid in testing_pids:\n",
    "        image_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}.IMAGE.nii.gz\")))\n",
    "        label_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}.LABEL.nii.gz\")))\n",
    "        for i in range (len(image_paths)):\n",
    "            testing_data.append({'image': image_paths[i], 'label': label_paths[i]})\n",
    "\n",
    "\n",
    "    testing_dataset = Dataset(testing_data, transform.Compose(preprocessing_transforms))\n",
    "    simCT_testing_dataloader = DataLoader(testing_dataset,  num_workers = 1, batch_size = 1, shuffle = False, collate_fn = pad_list_data_collate, pin_memory = True)\n",
    "    testing_sets = [\n",
    "        ('simCT', simCT_testing_dataloader)\n",
    "    ]\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# For CCTA\n",
    "# ----------------------------------------------------------------\n",
    "elif mode.upper() == \"CCTA\":\n",
    "    main_path = os.path.join(master_src, \"CCTA\")\n",
    "\n",
    "    UW_testing_pids = [3] # PLACEHOLDER FOR REAL TESTING SET\n",
    "    testing_pids = [f'UW_CCTA_{pid:03d}' for pid in UW_testing_pids]\n",
    "    testing_data = []\n",
    "\n",
    "    for pid in testing_pids:\n",
    "        image_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}.IMAGE.nii.gz\")))\n",
    "        label_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}.LABEL.nii.gz\")))\n",
    "        for i in range (len(image_paths)):\n",
    "            testing_data.append({'image': image_paths[i], 'label': label_paths[i]})\n",
    "\n",
    "        testing_dataset = Dataset(testing_data, transform.Compose(preprocessing_transforms))\n",
    "        CCTA_testing_dataloader = DataLoader(testing_dataset,  num_workers = 1, batch_size = 1, shuffle = False, collate_fn = pad_list_data_collate, pin_memory = True)\n",
    "        testing_sets = [\n",
    "            ('CCTA', CCTA_testing_dataloader)\n",
    "        ]\n",
    "\n",
    "else:\n",
    "    raise ValueError(f'{mode=} not found, arguments include: {mode_options}')\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "print(f'Running {mode=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up basic post-proessing for the prediction output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Of the combined output, what channels correspond to what group\n",
    "# Note, each group has it's own set of backgrounds\n",
    "grps = [\n",
    "        [0, 1],\n",
    "        [2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "        [12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "        [21, 22, 23]\n",
    "    ]\n",
    "\n",
    "# Defining how to convert from the predicted logits to binary classification\n",
    "label_OneHot_fns = {i: AsDiscrete(to_onehot=len(grp)) for i, grp in enumerate(grps)}\n",
    "\n",
    "# Metrics for comparison against the output\n",
    "dice_fn = DiceMetric(include_background = True, reduction = 'none', get_not_nans = False)\n",
    "hd95 = HausdorffDistanceMetric(include_background=True, percentile=95, reduction='none')\n",
    "msd = SurfaceDistanceMetric(include_background=True, reduction='none')\n",
    "metric_fns: dict[str, CumulativeIterationMetric] = {\n",
    "    'dice': dice_fn,\n",
    "    'hd95': hd95,\n",
    "    'msd': msd\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the model\n",
    "model_path = 'Experiments/MAGIC_ForWorking/Best_Val_dice'\n",
    "\n",
    "# Loading the model & send to cuda\n",
    "magic = MAGIC_framework.load_magic(model_path).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model on a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracking the images, predictions, and labels\n",
    "images, predictions, labels = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Set up in way that matches the training loop\n",
    "    for modality, testing_dataloader in testing_sets:\n",
    "        print(f'Looking at {modality} inputs')\n",
    "        for k in metric_fns.keys(): metric_fns[k].reset()\n",
    "\n",
    "        # Testing loop\n",
    "        for i, ds in enumerate(testing_dataloader):\n",
    "            print(f'  Working on {i=}')\n",
    "\n",
    "            # Pull the data from the dataloader\n",
    "            image = ds['image'].to(device)\n",
    "            # The label is stored as N differend sub-groups for the multi-task learning\n",
    "            # Apply a label OneHot transform to each individual label and stack them into a combined label\n",
    "            # Note: Background is NOT included\n",
    "            master_label: list[torch.Tensor] = torch.concatenate([label_OneHot_fns[i](ds[f'g{i}'][0])[1:].unsqueeze(0) for i in range(len(grps))], dim=1).to(device)\n",
    "\n",
    "            # Load the modality-specific model and run a sliding window inference\n",
    "            full_prediction = sliding_window_inference(\n",
    "                inputs=image,\n",
    "                roi_size=magic.config['roi_size'],\n",
    "                sw_batch_size=2,\n",
    "                predictor=magic.tricks[modality],\n",
    "                overlap=0.9\n",
    "            )\n",
    "\n",
    "            # Perform an argmax on each output group within the combined prediction\n",
    "            # Remove the background from each group and stack back into a combined prediction\n",
    "            full_prediction = argmax_with_multiOutput(full_prediction[0], [len(x) for x in grps])\n",
    "\n",
    "            # Record the preictions / labels / images if needed\n",
    "            images.append(image.cpu().numpy()[0, 0])\n",
    "            labels.append(master_label.cpu().numpy())\n",
    "            predictions.append(full_prediction.cpu().numpy())\n",
    "            \n",
    "            # Run the predictions\n",
    "            for k in metric_fns.keys(): metric_fns[k](full_prediction.unsqueeze(0), master_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregates = {k: metric_fns[k].aggregate()[:10] for k in metric_fns.keys()}\n",
    "_hd95 = aggregates['hd95'].detach().cpu().numpy() * 1.5\n",
    "_msd = aggregates['msd'].detach().cpu().numpy() * 1.5\n",
    "_dice = aggregates['dice'].detach().cpu().numpy()\n",
    "name_map = {0: 'WH', 1: 'RA', 2: 'LA', 3: 'RV', 4: 'LV', 5: 'AA', 6: 'SVC', 7: 'IVC', 8: 'PA', 9: 'PVs', 10: 'LMCA', 11: 'LADA', 12: 'RCA', 13: 'LCx', 14: 'V-AV', 15: 'V-PV', 16: 'V-TV', 17: 'V-MV', 18: 'N-SA', 19: 'N-AV'}\n",
    "line_report = \"{:>5} || {:0.3f} ± {:0.3f} || {:6.3f} ± {:6.3f} mm || {:6.3f} ± {:6.3f} mm\"\n",
    "top_line = f'{\"Str\":>5} || {\"Dice\":^13} || {\"HD95\":^18} || {\"MSD\":^18}'\n",
    "print(\"{:^{}}\".format('VR Inputs', len(top_line)))\n",
    "print(top_line)\n",
    "print('='*len(top_line))\n",
    "for i in range(20): print(line_report.format(name_map[i], np.nanmean(_dice[:, i]), np.nanstd(_dice[:, i]), np.nanmean(_hd95[:, i]), np.nanstd(_hd95[:, i]), np.nanmean(_msd[:, i]), np.nanstd(_msd[:, i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cardiac_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
