{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, datetime\n",
    "from typing import Optional\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "from torch.backends import cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "# Monai\n",
    "from monai.data.dataset import Dataset\n",
    "from monai.metrics import DiceMetric, HausdorffDistanceMetric, SurfaceDistanceMetric, CumulativeIterationMetric\n",
    "from monai.data.utils import pad_list_data_collate\n",
    "from monai.data.dataloader import DataLoader\n",
    "from monai.inferers.utils import sliding_window_inference\n",
    "import monai.transforms as transform\n",
    "from monai.transforms import AsDiscrete\n",
    "\n",
    "# Other\n",
    "import numpy as np\n",
    "\n",
    "# Local\n",
    "from MAGIC import grow_forest\n",
    "\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model info...\n",
      "4 5 False\n",
      "4 4\n",
      "[2, 10, 9, 3]\n",
      "[2, 10, 9, 3]\n",
      "[2, 10, 9, 3]\n",
      "[2, 10, 9, 3]\n",
      "[2, 10, 9, 3]\n",
      "Loading the models...\n",
      "Done.\n",
      "grps=[[0, 1], [2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17, 18, 19, 20], [21, 22, 23]]\n",
      "idx_grps=[[0], [1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15, 16, 17], [18, 19]]\n"
     ]
    }
   ],
   "source": [
    "src = \"MAGIC_experiments/PaperModel/Best_Val_dice\"\n",
    "\n",
    "forest = grow_forest.load_forest(src, pickle_name_forTraining=None).to(device)\n",
    "\n",
    "ogrps = forest.config['decoder_module'][1]['out_groups']\n",
    "grps = []\n",
    "for ngrp in ogrps:\n",
    "    s = sum([len(l) for l in grps])\n",
    "    grp = [s + i for i in range(ngrp)]\n",
    "    grps.append(grp)\n",
    "print(f'{grps=}')\n",
    "\n",
    "idx_grps = [[g - i - 1 for g in _grp[1:]] for i, _grp in enumerate(grps)]\n",
    "print(f\"{idx_grps=}\")\n",
    "group_idxs = [i for grp in idx_grps for i in grp]\n",
    "# grps = [[g + ng + 1 for g in [grp[0]-1] + grp] for ng, grp in enumerate(idx_grps)]\n",
    "out_groups = [len(grp) for grp in grps]\n",
    "num_classes_set = [sum(out_groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_src = \"/path/to/data/location\"\n",
    "\n",
    "image_keys = ['image']\n",
    "real_keys = image_keys + ['label']\n",
    "all_keys = image_keys + [f'g{i}' for i in range(4)]\n",
    "\n",
    "class split_groups:\n",
    "    def __init__(self, target_key: str, group_idxs: list[list[int]], out_names: list[str], stacking_order: Optional[list[list[int]]] = None):\n",
    "        self.tk = target_key\n",
    "        self.group_idxs = group_idxs\n",
    "        self.out_names = out_names\n",
    "        self.stacking_order = stacking_order if stacking_order is not None else [[i for i in range(len(g))] for g in group_idxs]\n",
    "\n",
    "    def __call__(self, d: dict):\n",
    "        d = dict(d)\n",
    "        src_arr = d[self.tk]\n",
    "        for gidx, gname, gorder in zip(self.group_idxs, self.out_names, self.stacking_order):\n",
    "            base = np.zeros(src_arr.shape[1:]) if isinstance(src_arr, np.ndarray) else torch.zeros(src_arr.shape[1:], dtype=src_arr.dtype)\n",
    "            glabel = src_arr[gidx]\n",
    "            for i in gorder:\n",
    "                base[glabel[i] == 1] = i + 1\n",
    "            d[gname] = base[None]\n",
    "        return d\n",
    "    \n",
    "class channel_to_stacked_binary:\n",
    "    def __init__(self, target_key: str, out_key: str):\n",
    "        self.tk = target_key\n",
    "        self.ok = out_key\n",
    "    \n",
    "    def __call__(self, d: dict):\n",
    "        d = dict(d)\n",
    "        base = d[self.tk]\n",
    "        d[self.ok] = base.sum(0)[None] > 1\n",
    "        return d\n",
    "\n",
    "preprocessing_transforms = [\n",
    "    transform.LoadImaged(real_keys),\n",
    "    split_groups(\n",
    "        target_key='label',\n",
    "        group_idxs=idx_grps,\n",
    "        out_names=[f'g{i}' for i in range(len(grps))],\n",
    "        stacking_order=None,\n",
    "        ),\n",
    "    channel_to_stacked_binary('label', 'blabel'),\n",
    "    transform.NormalizeIntensityd(image_keys, nonzero=True), #z-score normalization that helps consistancy with patient to patient and brings mean to zero to help with deep learning\n",
    "]\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# For ViewRay\n",
    "# ----------------------------------------------------------------\n",
    "main_path = os.path.join(master_src, \"VR\")\n",
    "\n",
    "testing_data = []\n",
    "HF_testing_pids = [1, 18, 29, 35, 36]\n",
    "testing_pids = [f'HF_VR_{pid:02d}' for pid in HF_testing_pids]\n",
    "UW_testing_pids = [1, 2, 3, 4, 5]#, 6, 7, 8, 9, 10]\n",
    "testing_pids += [f'UW_VR_{pid:02d}' for pid in UW_testing_pids]\n",
    "\n",
    "for pid in testing_pids:\n",
    "    image_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}_SIM.IMAGE.nii.gz\")))\n",
    "    label_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}_SIM.LABEL.nii.gz\")))\n",
    "    for i in range (len(image_paths)):\n",
    "        testing_data.append({'image': image_paths[i], 'label': label_paths[i]})\n",
    "\n",
    "testing_dataset = Dataset(testing_data, transform.Compose(preprocessing_transforms))\n",
    "VR_testing_dataloader = DataLoader(testing_dataset,  num_workers = 1, batch_size = 1, shuffle = False, collate_fn = pad_list_data_collate, pin_memory = True)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# For simCT\n",
    "# ----------------------------------------------------------------\n",
    "main_path = os.path.join(master_src, \"simCT\")\n",
    "HF_testing_pids = [13, 22, 28, 29, 34]\n",
    "testing_pids = [f'HF_simCT_{pid:02d}' for pid in HF_testing_pids]\n",
    "UW_testing_pids = [16, 18, 22, 28, 32]\n",
    "testing_pids += [f'UW_simCT_{pid:02d}' for pid in UW_testing_pids]\n",
    "\n",
    "testing_data = []\n",
    "for pid in testing_pids:\n",
    "    image_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}.IMAGE.nii.gz\")))\n",
    "    label_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}.LABEL.nii.gz\")))\n",
    "    for i in range (len(image_paths)):\n",
    "        testing_data.append({'image': image_paths[i], 'label': label_paths[i]})\n",
    "\n",
    "\n",
    "testing_dataset = Dataset(testing_data, transform.Compose(preprocessing_transforms))\n",
    "simCT_testing_dataloader = DataLoader(testing_dataset,  num_workers = 1, batch_size = 1, shuffle = False, collate_fn = pad_list_data_collate, pin_memory = True)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# For CCTA\n",
    "# ----------------------------------------------------------------\n",
    "main_path = os.path.join(master_src, \"CCTA\")\n",
    "\n",
    "UW_testing_pids = [112, 115, 127, 131, 145, 151, 153, 158, 162, 163]\n",
    "\n",
    "testing_pids = [f'UW_CCTA_{pid:03d}' for pid in UW_testing_pids]\n",
    "testing_data = []\n",
    "\n",
    "for pid in testing_pids:\n",
    "    image_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}.IMAGE.nii.gz\")))\n",
    "    label_paths = sorted(glob.glob(os.path.join(main_path, '*', f\"{pid}.LABEL.nii.gz\")))\n",
    "    for i in range (len(image_paths)):\n",
    "        testing_data.append({'image': image_paths[i], 'label': label_paths[i]})\n",
    "\n",
    "    testing_dataset = Dataset(testing_data, transform.Compose(preprocessing_transforms))\n",
    "    CCTA_testing_dataloader = DataLoader(testing_dataset,  num_workers = 1, batch_size = 1, shuffle = False, collate_fn = pad_list_data_collate, pin_memory = True)\n",
    "\n",
    "testing_sets = [\n",
    "    ('simCT', simCT_testing_dataloader),\n",
    "    ('VR', VR_testing_dataloader),\n",
    "    ('CCTA', CCTA_testing_dataloader),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_OneHot_fns = {i: AsDiscrete(to_onehot=len(grp)) for i, grp in enumerate(grps)}\n",
    "\n",
    "\n",
    "dice_fn = DiceMetric(include_background = True, reduction = 'none', get_not_nans = False)\n",
    "hd95 = HausdorffDistanceMetric(include_background=True, percentile=95, reduction='none')\n",
    "hd = HausdorffDistanceMetric(include_background=True, reduction='none')\n",
    "msd = SurfaceDistanceMetric(include_background=True, reduction='none')\n",
    "metric_fns: dict[str, CumulativeIterationMetric] = {\n",
    "    'dice': dice_fn,\n",
    "    'hd95': hd95,\n",
    "    'msd': msd,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupSeperate:\n",
    "    def __init__(self, idxs_groups: list[list[int]]): \n",
    "        self.idxs_groups = idxs_groups\n",
    "\n",
    "    def __call__(self, arr: torch.Tensor) -> tuple[torch.Tensor]:\n",
    "        return [arr[:, igrp] for igrp in self.idxs_groups]\n",
    "\n",
    "grp_seperator = GroupSeperate(grps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing modality='simCT'\n",
      "                      simCT Inputs                      \n",
      "  Str ||    Dice     ||      HD95      ||      MSD      \n",
      "========================================================\n",
      "   WH || 0.96 ± 0.01 ||  4.3 ±  1.4 mm ||  1.3 ±  0.4 mm\n",
      "   RA || 0.87 ± 0.06 ||  5.7 ±  2.5 mm ||  1.8 ±  0.9 mm\n",
      "   LA || 0.88 ± 0.03 ||  5.2 ±  1.4 mm ||  1.6 ±  0.4 mm\n",
      "   RV || 0.88 ± 0.05 ||  7.0 ±  4.2 mm ||  1.5 ±  0.4 mm\n",
      "   LV || 0.93 ± 0.02 ||  5.1 ±  2.4 mm ||  1.4 ±  0.4 mm\n",
      "   AA || 0.88 ± 0.06 ||  4.8 ±  2.8 mm ||  1.4 ±  0.6 mm\n",
      "  SVC || 0.80 ± 0.08 ||  4.8 ±  3.1 mm ||  1.6 ±  0.8 mm\n",
      "  IVC || 0.75 ± 0.11 ||  7.3 ±  3.2 mm ||  2.0 ±  1.0 mm\n",
      "   PA || 0.86 ± 0.04 ||  4.2 ±  1.9 mm ||  1.3 ±  0.5 mm\n",
      "  PVs || 0.76 ± 0.04 ||  5.1 ±  1.4 mm ||  1.3 ±  0.4 mm\n",
      " LMCA || 0.64 ± 0.10 ||  3.7 ±  0.9 mm ||  1.4 ±  0.4 mm\n",
      " LADA || 0.59 ± 0.13 ||  8.5 ±  4.1 mm ||  1.8 ±  0.7 mm\n",
      "  RCA || 0.57 ± 0.16 ||  6.4 ±  2.7 mm ||  1.7 ±  0.8 mm\n",
      "  LCx || 0.58 ± 0.10 ||  5.2 ±  1.8 mm ||  1.7 ±  0.5 mm\n",
      " V-AV || 0.71 ± 0.16 ||  3.8 ±  1.8 mm ||  2.0 ±  1.2 mm\n",
      " V-PV || 0.79 ± 0.17 ||  3.7 ±  2.1 mm ||  1.5 ±  1.1 mm\n",
      " V-TV || 0.67 ± 0.16 ||  5.7 ±  2.9 mm ||  2.0 ±  1.0 mm\n",
      " V-MV || 0.63 ± 0.20 ||  5.7 ±  2.8 mm ||  2.1 ±  1.0 mm\n",
      " N-SA || 0.65 ± 0.10 ||  4.8 ±  1.4 mm ||  2.2 ±  0.7 mm\n",
      " N-AV || 0.67 ± 0.14 ||  4.4 ±  1.8 mm ||  2.1 ±  0.9 mm\n",
      "\n",
      "Testing modality='VR'\n",
      "                       VR Inputs                        \n",
      "  Str ||    Dice     ||      HD95      ||      MSD      \n",
      "========================================================\n",
      "   WH || 0.94 ± 0.01 ||  5.3 ±  1.1 mm ||  1.8 ±  0.4 mm\n",
      "   RA || 0.84 ± 0.05 ||  6.9 ±  2.7 mm ||  2.3 ±  0.7 mm\n",
      "   LA || 0.87 ± 0.03 ||  6.2 ±  2.2 mm ||  1.8 ±  0.4 mm\n",
      "   RV || 0.86 ± 0.05 ||  6.0 ±  2.1 mm ||  2.1 ±  0.6 mm\n",
      "   LV || 0.93 ± 0.01 ||  4.3 ±  1.2 mm ||  1.5 ±  0.3 mm\n",
      "   AA || 0.84 ± 0.05 ||  6.1 ±  2.7 mm ||  2.1 ±  0.9 mm\n",
      "  SVC || 0.76 ± 0.16 ||  4.8 ±  3.0 mm ||  1.6 ±  0.8 mm\n",
      "  IVC || 0.57 ± 0.24 || 13.4 ±  9.0 mm ||  3.0 ±  1.9 mm\n",
      "   PA || 0.81 ± 0.07 ||  7.4 ±  6.3 mm ||  1.9 ±  0.7 mm\n",
      "  PVs || 0.62 ± 0.09 || 14.4 ±  9.6 mm ||  1.9 ±  0.6 mm\n",
      " LMCA || 0.51 ± 0.22 ||  6.3 ±  4.0 mm ||  2.4 ±  2.4 mm\n",
      " LADA || 0.61 ± 0.10 ||  6.7 ±  1.7 mm ||  2.0 ±  0.4 mm\n",
      "  RCA || 0.46 ± 0.20 ||  9.3 ±  4.9 mm ||  2.8 ±  1.5 mm\n",
      "  LCx || 0.41 ± 0.10 ||  8.0 ±  1.7 mm ||  2.4 ±  0.6 mm\n",
      " V-AV || 0.66 ± 0.10 ||  5.9 ±  1.4 mm ||  2.0 ±  0.7 mm\n",
      " V-PV || 0.66 ± 0.15 ||  7.2 ±  5.7 mm ||  2.4 ±  1.0 mm\n",
      " V-TV || 0.53 ± 0.21 ||  7.5 ±  2.7 mm ||  3.1 ±  1.5 mm\n",
      " V-MV || 0.64 ± 0.10 ||  6.6 ±  1.3 mm ||  2.3 ±  0.8 mm\n",
      " N-SA || 0.52 ± 0.14 ||  7.0 ±  2.1 mm ||  3.1 ±  1.1 mm\n",
      " N-AV || 0.52 ± 0.18 ||  7.0 ±  2.6 mm ||  2.8 ±  1.0 mm\n",
      "\n",
      "Testing modality='CCTA'\n",
      "                      CCTA Inputs                       \n",
      "  Str ||    Dice     ||      HD95      ||      MSD      \n",
      "========================================================\n",
      "   WH || 0.95 ± 0.01 ||  6.1 ±  2.7 mm ||  1.7 ±  0.4 mm\n",
      "   RA || 0.93 ± 0.01 ||  4.0 ±  1.0 mm ||  1.2 ±  0.2 mm\n",
      "   LA || 0.95 ± 0.01 ||  3.4 ±  1.3 mm ||  1.0 ±  0.2 mm\n",
      "   RV || 0.87 ± 0.04 ||  6.7 ±  3.7 mm ||  1.8 ±  0.5 mm\n",
      "   LV || 0.96 ± 0.01 ||  2.6 ±  0.5 mm ||  0.9 ±  0.1 mm\n",
      "   AA || 0.93 ± 0.02 ||  4.5 ±  2.0 mm ||  1.1 ±  0.4 mm\n",
      "  SVC || 0.85 ± 0.04 ||  4.9 ±  2.1 mm ||  1.2 ±  0.5 mm\n",
      "  IVC || 0.82 ± 0.05 ||  5.0 ±  2.0 mm ||  1.5 ±  0.7 mm\n",
      "   PA || 0.84 ± 0.05 ||  8.1 ±  5.3 mm ||  1.6 ±  0.6 mm\n",
      "  PVs || 0.78 ± 0.03 ||  7.8 ±  2.0 mm ||  1.0 ±  0.2 mm\n",
      " LMCA || 0.73 ± 0.07 ||  4.1 ±  2.5 mm ||  1.0 ±  0.4 mm\n",
      " LADA || 0.80 ± 0.06 ||  4.3 ±  2.4 mm ||  0.8 ±  0.3 mm\n",
      "  RCA || 0.86 ± 0.04 ||  4.9 ±  3.9 mm ||  0.4 ±  0.1 mm\n",
      "  LCx || 0.67 ± 0.16 ||  8.4 ±  7.0 mm ||  1.1 ±  0.7 mm\n",
      " V-AV || 0.77 ± 0.13 ||  3.0 ±  1.0 mm ||  1.4 ±  0.7 mm\n",
      " V-PV || 0.38 ± 0.25 ||  9.7 ±  5.1 mm ||  4.5 ±  3.3 mm\n",
      " V-TV || 0.73 ± 0.11 ||  3.7 ±  1.2 mm ||  1.6 ±  0.5 mm\n",
      " V-MV || 0.84 ± 0.04 ||  3.0 ±  0.7 mm ||  0.9 ±  0.2 mm\n",
      " N-SA || 0.71 ± 0.12 ||  3.9 ±  1.5 mm ||  1.9 ±  0.8 mm\n",
      " N-AV || 0.73 ± 0.11 ||  3.7 ±  1.5 mm ||  1.9 ±  0.7 mm\n",
      "\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "with torch.no_grad():\n",
    "    for modality, testing_dataloader in testing_sets:\n",
    "        net_key = f\"{modality}_0\"\n",
    "        print(f'Testing {modality=}')\n",
    "        for k in metric_fns.keys(): metric_fns[k].reset()\n",
    "            \n",
    "        for ds in testing_dataloader:\n",
    "            image = ds['image'].to(device)\n",
    "            master_labels: list[torch.Tensor] = [label_OneHot_fns[i](ds[f'g{i}'][0])[1:].unsqueeze(0).to(device) for i in range(len(grps))]\n",
    "            \n",
    "            start = datetime.datetime.now()\n",
    "            full_prediction = sliding_window_inference(inputs = image, roi_size=forest.config['roi_size'], sw_batch_size=1, predictor=forest.trees[net_key], overlap=0.9)\n",
    "            end = datetime.datetime.now()\n",
    "            times.append(end - start)\n",
    "\n",
    "            grp_predictions = grp_seperator(full_prediction)\n",
    "\n",
    "            _predictions = []\n",
    "            for ii in range(len(grps)):\n",
    "                _out = label_OneHot_fns[ii](torch.argmax(grp_predictions[ii], dim=1))[1:].unsqueeze(0)\n",
    "                _predictions.append(_out)\n",
    "            _predictions = torch.concatenate(_predictions, dim=1)\n",
    "            _master_labels = torch.concatenate(master_labels, dim=1)\n",
    "\n",
    "            for k in metric_fns.keys(): \n",
    "                metric_fns[k](_predictions.cpu(), _master_labels.cpu())\n",
    "\n",
    "        aggregates = {k: metric_fns[k].aggregate()[:10] for k in metric_fns.keys()}\n",
    "        _hd95 = aggregates['hd95'].detach().cpu().numpy() * 1.5\n",
    "        _msd = aggregates['msd'].detach().cpu().numpy() * 1.5\n",
    "        _dice = aggregates['dice'].detach().cpu().numpy()\n",
    "        name_map = {0: 'WH', 1: 'RA', 2: 'LA', 3: 'RV', 4: 'LV', 5: 'AA', 6: 'SVC', 7: 'IVC', 8: 'PA', 9: 'PVs', 10: 'LMCA', 11: 'LADA', 12: 'RCA', 13: 'LCx', 14: 'V-AV', 15: 'V-PV', 16: 'V-TV', 17: 'V-MV', 18: 'N-SA', 19: 'N-AV'}\n",
    "        line_report = \"{:>5} || {:0.2f} ± {:0.2f} || {:4.1f} ± {:4.1f} mm || {:4.1f} ± {:4.1f} mm\"\n",
    "        top_line = f'{\"Str\":>5} || {\"Dice\":^11} || {\"HD95\":^14} || {\"MSD\":^14}'\n",
    "        print(\"{:^{}}\".format(f'{modality} Inputs', len(top_line)))\n",
    "        print(top_line)\n",
    "        print('='*len(top_line))\n",
    "        for i in range(20): print(line_report.format(name_map[i], np.nanmean(_dice[:, i]), np.nanstd(_dice[:, i]), np.nanmean(_hd95[:, i]), np.nanstd(_hd95[:, i]), np.nanmean(_msd[:, i]), np.nanstd(_msd[:, i])))\n",
    "        print()            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cardiac_3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
